{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJPwhizQmZBF",
        "outputId": "79b3515e-eb21-40ce-ea67-caf237cdf7da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.8/dist-packages (1.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from stanza) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stanza) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from stanza) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from stanza) (1.13.0+cu116)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.8/dist-packages (from stanza) (2.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install stanza\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uQYvqGjHo4WZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import json\n",
        "import stanza\n",
        "from tensorflow.keras import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import TFRobertaModel,RobertaTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QPFbHwpRpB2z"
      },
      "outputs": [],
      "source": [
        "test_set = pd.read_csv(\"tsd_test.csv\") # Read the test dataset\n",
        "test_set['spans'] = test_set['spans'].apply(lambda x : json.loads(x)) # Extract the spans to a List\n",
        "train_set = pd.read_csv(\"tsd_train.csv\") # Read the training dataset\n",
        "train_set['spans'] = train_set['spans'].apply(lambda x : json.loads(x)) # Extract the spans to a List"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toxic_span_dataset = test_set.append(train_set, ignore_index = True)\n",
        "# toxic_span_dataset['text'] = toxic_span_dataset['text'].apply(lambda x : x.lower())"
      ],
      "metadata": {
        "id": "WUk2NV8z5svl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwkrLuam4HeD",
        "outputId": "5a258d4c-9c49-48e2-d2de-b050b9652130"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spans    object\n",
            "text     object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orrUexKD4UxG",
        "outputId": "4b5e13d5-0bc5-474f-da93-b4dcafc0ca87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  spans  \\\n",
            "0     [84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135...   \n",
            "1                              [81, 82, 83, 84, 85, 86]   \n",
            "2                                                    []   \n",
            "3                                                    []   \n",
            "4                                                    []   \n",
            "...                                                 ...   \n",
            "1995  [4, 5, 6, 7, 8, 70, 71, 72, 73, 74, 75, 76, 77...   \n",
            "1996                               [23, 24, 25, 26, 27]   \n",
            "1997  [157, 158, 159, 160, 161, 162, 163, 164, 165, ...   \n",
            "1998                                                 []   \n",
            "1999                               [828, 829, 830, 831]   \n",
            "\n",
            "                                                   text  \n",
            "0     That's right. They are not normal. And I am st...  \n",
            "1     \"Watch people die from taking away their healt...  \n",
            "2     tens years ago i contacted the PDR and suggest...  \n",
            "3     The parallels between the ANC and the Sicilian...  \n",
            "4     Intel Community: ‘How can we work for a Presid...  \n",
            "...                                                 ...  \n",
            "1995  hey loser change your name to something more a...  \n",
            "1996  And you are a complete moron who obviously doe...  \n",
            "1997  Such vitriol from the left.  Who would have th...  \n",
            "1998  It is now time for most of you to expand your ...  \n",
            "1999  Why does this author think she can demand, or ...  \n",
            "\n",
            "[2000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set['spans'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rM0OTO5104V",
        "outputId": "9023d66e-37ef-4664-e2b4-f60a72dbf8c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       [84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135...\n",
            "1                                [81, 82, 83, 84, 85, 86]\n",
            "2                                                      []\n",
            "3                                                      []\n",
            "4                                                      []\n",
            "                              ...                        \n",
            "1995    [4, 5, 6, 7, 8, 70, 71, 72, 73, 74, 75, 76, 77...\n",
            "1996                                 [23, 24, 25, 26, 27]\n",
            "1997    [157, 158, 159, 160, 161, 162, 163, 164, 165, ...\n",
            "1998                                                   []\n",
            "1999                                 [828, 829, 830, 831]\n",
            "Name: spans, Length: 2000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsJqHF451704",
        "outputId": "e63ccc7b-b72d-4ace-cc7d-88aa13bd4201"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_set['spans']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awhunwLa3GK3",
        "outputId": "ed1aa9d3-3f47-4065-fba6-3afbfcbdafe1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set['spans'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toChji6Y3unB",
        "outputId": "3040f8fa-48fe-4a02-e22e-56486a01d624"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       [84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135...\n",
            "1                                [81, 82, 83, 84, 85, 86]\n",
            "2                                                      []\n",
            "3                                                      []\n",
            "4                                                      []\n",
            "                              ...                        \n",
            "1995    [4, 5, 6, 7, 8, 70, 71, 72, 73, 74, 75, 76, 77...\n",
            "1996                                 [23, 24, 25, 26, 27]\n",
            "1997    [157, 158, 159, 160, 161, 162, 163, 164, 165, ...\n",
            "1998                                                   []\n",
            "1999                                 [828, 829, 830, 831]\n",
            "Name: spans, Length: 2000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_set['spans'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLx0VF4a34D_",
        "outputId": "a1b42cb1-4e9b-4323-e23a-ae06bb6605ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set['spans'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkSMdrC53_BX",
        "outputId": "c8fb2067-88b2-485b-9da9-923d9ee68356"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_set['text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVhzo6534bXU",
        "outputId": "2ab78d79-fdb5-4ab2-f17a-9622436a1ce6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEHIHGQr4M1t",
        "outputId": "4c83e626-2f3a-4fad-d6c9-ff71e16463bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       That's right. They are not normal. And I am st...\n",
            "1       \"Watch people die from taking away their healt...\n",
            "2       tens years ago i contacted the PDR and suggest...\n",
            "3       The parallels between the ANC and the Sicilian...\n",
            "4       Intel Community: ‘How can we work for a Presid...\n",
            "                              ...                        \n",
            "1995    hey loser change your name to something more a...\n",
            "1996    And you are a complete moron who obviously doe...\n",
            "1997    Such vitriol from the left.  Who would have th...\n",
            "1998    It is now time for most of you to expand your ...\n",
            "1999    Why does this author think she can demand, or ...\n",
            "Name: text, Length: 2000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_set['text'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbFslqO74kMd",
        "outputId": "032e0fd0-42bc-4eb6-c634-eaa9add4008b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n5-CCMg4thq",
        "outputId": "76c40e46-06e1-4bc0-bbc0-2745bab8382f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's right. They are not normal. And I am starting from the premise that they are ABNORMAL. Proceed wth the typical racist, bigot, sexist rubbish.\n",
            "Thanks!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHVCDR-b6CW9",
        "outputId": "ab54f518-4a2a-4819-eb09-1a7ad09f1123"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  spans  \\\n",
            "0     [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
            "1                          [33, 34, 35, 36, 37, 38, 39]   \n",
            "2                                          [0, 1, 2, 3]   \n",
            "3             [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
            "4                          [32, 33, 34, 35, 36, 37, 38]   \n",
            "...                                                 ...   \n",
            "7934                                     [8, 9, 10, 11]   \n",
            "7935  [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...   \n",
            "7936  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
            "7937                            [5, 6, 7, 8, 9, 10, 11]   \n",
            "7938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...   \n",
            "\n",
            "                                                   text  \n",
            "0     Another violent and aggressive immigrant killi...  \n",
            "1     I am 56 years old, I am not your fucking junio...  \n",
            "2                     Damn, a whole family. Sad indeed.  \n",
            "3     What a knucklehead. How can anyone not know th...  \n",
            "4     \"who do you think should do the killing?\"\\n\\nA...  \n",
            "...                                                 ...  \n",
            "7934                             Another fool pipes in.  \n",
            "7935  So if a restaurant owner puts up a sign saying...  \n",
            "7936  Any faith that can't stand up to logic and rea...  \n",
            "7937  This idiotic. Use the surplus to pay down the ...  \n",
            "7938  Who is this \"we\" of which you speak? Are you r...  \n",
            "\n",
            "[7939 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKFQIAMr6I6h",
        "outputId": "2b3fa1ac-37dc-4da5-945c-3aa785bce3a8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(toxic_span_dataset))"
      ],
      "metadata": {
        "id": "nAYmBu3n6VkX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(toxic_span_dataset)"
      ],
      "metadata": {
        "id": "8KwqE9Xt55Fv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1WeC4OEvpVAN"
      },
      "outputs": [],
      "source": [
        "def createNEROutputs(texts, spans, max_length, tokenizer):\n",
        "    outputs = []\n",
        "    for text,span in zip(texts,spans):\n",
        "        output = np.zeros(max_length*3,dtype=np.float).reshape((max_length,3))\n",
        "        tokens = tokenizer.tokenize(text)[:max_length]\n",
        "        length = 0\n",
        "        start = True\n",
        "        for i in range(len(tokens),max_length):\n",
        "            output[i,0] = 1.0\n",
        "        for index,token in enumerate(tokens):\n",
        "            sub = True\n",
        "            if \"Ġ\" in token:\n",
        "                sub = False\n",
        "                token = token[1:]\n",
        "            if not start:\n",
        "                next_index = text[length:].find(token)\n",
        "                if next_index == 0:\n",
        "                    sub = True\n",
        "                length += next_index\n",
        "            # if length in span and not sub:\n",
        "            #     output[index,2] = 1.0\n",
        "            #     output[index,0] = 0.0\n",
        "            if length in span:\n",
        "                output[index,2] = 1.0\n",
        "                output[index,0] = 0.0\n",
        "            else:\n",
        "                output[index,1] = 1.0\n",
        "                output[index,0] = 0.0\n",
        "            length += len(token)\n",
        "            start = False\n",
        "        outputs.append(output)\n",
        "    return np.array(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOdjt3kIoT4s"
      },
      "source": [
        "9700*400*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MW7eanEmpX8s"
      },
      "outputs": [],
      "source": [
        "def NERGetIndicesSingleText(outputs,text,tokenizer):\n",
        "    outputs = tf.argmax(outputs,axis=-1)\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    index = 0\n",
        "    indexes = []\n",
        "    sub = False\n",
        "    prev = False\n",
        "    for token,output in zip(tokens,outputs):\n",
        "        if token[0] == \"Ġ\":\n",
        "            token = token[1:]\n",
        "            sub = False\n",
        "        elif token.isalpha():\n",
        "            sub = True\n",
        "        else:\n",
        "            sub = False\n",
        "        temp_index = text[index:].find(token)\n",
        "        temp_start = index+temp_index\n",
        "        if output == 2 or (sub and prev and output != 0):\n",
        "            prev = True\n",
        "            indexes = indexes + list(range(temp_start,temp_start+len(token)))\n",
        "        else:\n",
        "            prev = False\n",
        "        index = temp_start+len(token)\n",
        "    return np.array(indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gE7OcqeQpbJu"
      },
      "outputs": [],
      "source": [
        "def createIndicesForNERModel(predicts,texts,tokenizer):\n",
        "    outputs = []\n",
        "    for text,pred in zip(texts,predicts):\n",
        "         indices = NERGetIndicesSingleText(pred,text,tokenizer)\n",
        "         outputs.append(indices)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NMGZAhUTpd2B"
      },
      "outputs": [],
      "source": [
        "def f1(preds,trues):\n",
        "    if len(trues) == 0:\n",
        "        return 1. if len(preds) == 0 else 0.\n",
        "    if len(preds) == 0:\n",
        "        return 0.\n",
        "    predictions_set = set(preds)\n",
        "    gold_set = set(trues)\n",
        "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
        "    denom = len(predictions_set) + len(gold_set)\n",
        "    return float(nom)/float(denom)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "S9FhUT2wpf8v"
      },
      "outputs": [],
      "source": [
        "def avg_f1(preds,trues):\n",
        "    avg_f1_total = 0.0\n",
        "    for pred,true in zip(preds,trues):\n",
        "        avg_f1_total += f1(pred,true)\n",
        "    return avg_f1_total/len(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "y7ot-HLupim3"
      },
      "outputs": [],
      "source": [
        "class F1Metric(callbacks.Callback):\n",
        "    def __init__(self,inputs,labels,spans,texts,test=True):\n",
        "        self.inputs = inputs\n",
        "        self.spans = spans\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = texts\n",
        "        self.test = test\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        preds = self.model.predict(self.inputs,verbose=0)\n",
        "        indices = createIndicesForNERModel(preds,texts,tokenizer)\n",
        "        f1 = avg_f1(indices,self.spans)\n",
        "        if self.test:\n",
        "            print()\n",
        "            print(\"test f1 = \"+str(f1))\n",
        "        else:\n",
        "            print()\n",
        "            print(\"train f1 = \"+str(f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "R-awAKF7poKj"
      },
      "outputs": [],
      "source": [
        "def createInputForNER(texts, max_length, tokenizer):\n",
        "    input_length = []\n",
        "    for text in texts:\n",
        "        input_length.append(min(max_length,len(tokenizer.tokenize(text))))\n",
        "    tokens = tokenizer(texts,padding=\"max_length\",max_length=max_length,return_tensors=\"tf\",truncation=True)\n",
        "    data = [np.array(tokens['input_ids']),np.array(tokens['attention_mask']),np.array(input_length)]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS5DNwpSqmUq",
        "outputId": "761a6d3e-cafd-4e76-bd5a-f273560bd274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.8/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons==0.16.1) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.16.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM84dvcbpt07",
        "outputId": "69ea171c-7ba9-4cdc-b2ec-06b31873709a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.9.2 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "try:\n",
        "    from tensorflow.contrib.crf import crf_decode\n",
        "except ImportError:\n",
        "    from tensorflow.python.framework import dtypes\n",
        "    from tensorflow.python.ops import array_ops, gen_array_ops, math_ops, rnn, rnn_cell\n",
        "\n",
        "\n",
        "    class CrfDecodeForwardRnnCell(rnn_cell.RNNCell):\n",
        "        def __init__(self, transition_params):\n",
        "            self._transition_params = array_ops.expand_dims(transition_params, 0)\n",
        "            self._num_tags = transition_params.get_shape()[0]\n",
        "\n",
        "        @property\n",
        "        def state_size(self):\n",
        "            return self._num_tags\n",
        "\n",
        "        @property\n",
        "        def output_size(self):\n",
        "            return self._num_tags\n",
        "\n",
        "        def __call__(self, inputs, state, scope=None):\n",
        "            state = array_ops.expand_dims(state, 2)  # [B, O, 1]\n",
        "            transition_scores = state + self._transition_params  # [B, O, O]\n",
        "            new_state = inputs + math_ops.reduce_max(transition_scores, [1])  # [B, O]\n",
        "            backpointers = math_ops.argmax(transition_scores, 1)\n",
        "            backpointers = math_ops.cast(backpointers, dtype=dtypes.int32)  # [B, O]\n",
        "            return backpointers, new_state\n",
        "\n",
        "\n",
        "    class CrfDecodeBackwardRnnCell(rnn_cell.RNNCell):\n",
        "        def __init__(self, num_tags):\n",
        "            self._num_tags = num_tags\n",
        "\n",
        "        @property\n",
        "        def state_size(self):\n",
        "            return 1\n",
        "\n",
        "        @property\n",
        "        def output_size(self):\n",
        "            return 1\n",
        "\n",
        "        def __call__(self, inputs, state, scope=None):\n",
        "            state = array_ops.squeeze(state, axis=[1])  # [B]\n",
        "            batch_size = array_ops.shape(inputs)[0]\n",
        "            b_indices = math_ops.range(batch_size)  # [B]\n",
        "            indices = array_ops.stack([b_indices, state], axis=1)  # [B, 2]\n",
        "            new_tags = array_ops.expand_dims(\n",
        "                gen_array_ops.gather_nd(inputs, indices),  # [B]\n",
        "                axis=-1)  # [B, 1]\n",
        "\n",
        "            return new_tags, new_tags\n",
        "\n",
        "\n",
        "    def crf_decode(potentials, transition_params, sequence_length):\n",
        "        num_tags = potentials.get_shape()[2]\n",
        "\n",
        "        # Computes forward decoding. Get last score and backpointers.\n",
        "        crf_fwd_cell = CrfDecodeForwardRnnCell(transition_params)\n",
        "        initial_state = array_ops.slice(potentials, [0, 0, 0], [-1, 1, -1])\n",
        "        initial_state = array_ops.squeeze(initial_state, axis=[1])  # [B, O]\n",
        "        inputs = array_ops.slice(potentials, [0, 1, 0], [-1, -1, -1])  # [B, T-1, O]\n",
        "        backpointers, last_score = rnn.dynamic_rnn(\n",
        "            crf_fwd_cell,\n",
        "            inputs=inputs,\n",
        "            sequence_length=sequence_length - 1,\n",
        "            initial_state=initial_state,\n",
        "            time_major=False,\n",
        "            dtype=dtypes.int32)  # [B, T - 1, O], [B, O]\n",
        "        backpointers = gen_array_ops.reverse_sequence(backpointers, sequence_length - 1, seq_dim=1)  # [B, T-1, O]\n",
        "\n",
        "        # Computes backward decoding. Extract tag indices from backpointers.\n",
        "        crf_bwd_cell = CrfDecodeBackwardRnnCell(num_tags)\n",
        "        initial_state = math_ops.cast(math_ops.argmax(last_score, axis=1), dtype=dtypes.int32)  # [B]\n",
        "        initial_state = array_ops.expand_dims(initial_state, axis=-1)  # [B, 1]\n",
        "        decode_tags, _ = rnn.dynamic_rnn(\n",
        "            crf_bwd_cell,\n",
        "            inputs=backpointers,\n",
        "            sequence_length=sequence_length - 1,\n",
        "            initial_state=initial_state,\n",
        "            time_major=False,\n",
        "            dtype=dtypes.int32)  # [B, T - 1, 1]\n",
        "        decode_tags = array_ops.squeeze(decode_tags, axis=[2])  # [B, T - 1]\n",
        "        decode_tags = array_ops.concat([initial_state, decode_tags], axis=1)  # [B, T]\n",
        "        decode_tags = gen_array_ops.reverse_sequence(decode_tags, sequence_length, seq_dim=1)  # [B, T]\n",
        "\n",
        "        best_score = math_ops.reduce_max(last_score, axis=1)  # [B]\n",
        "        return decode_tags, best_score\n",
        "\n",
        "\n",
        "class CRFLayer(Layer):\n",
        "\n",
        "    def __init__(self, transition_params=None, **kwargs):\n",
        "        super(CRFLayer, self).__init__(**kwargs)\n",
        "        self.transition_params = transition_params\n",
        "        self.input_spec = [InputSpec(ndim=3), InputSpec(ndim=2)]\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape[0]) == 3\n",
        "\n",
        "        return input_shape[0]\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 2\n",
        "        assert len(input_shape[0]) == 3\n",
        "        assert len(input_shape[1]) == 2\n",
        "        n_steps = input_shape[0][1]\n",
        "        n_classes = input_shape[0][2]\n",
        "        assert n_steps is None or n_steps >= 2\n",
        "\n",
        "        self.transition_params = self.add_weight(shape=(n_classes, n_classes),\n",
        "                                                 initializer='uniform',\n",
        "                                                 name='transition')\n",
        "        self.input_spec = [InputSpec(dtype=K.floatx(), shape=(None, n_steps, n_classes)),\n",
        "                           InputSpec(dtype='int32', shape=(None, 1))]\n",
        "        self.built = True\n",
        "\n",
        "    def viterbi_decode(self, potentials, sequence_length):\n",
        "        decode_tags, best_score = crf_decode(potentials, self.transition_params, sequence_length)\n",
        "        return decode_tags\n",
        "\n",
        "    def call(self, inputs, mask=None, **kwargs):\n",
        "        inputs, sequence_lengths = inputs\n",
        "        self.sequence_lengths = K.flatten(sequence_lengths)\n",
        "        y_pred = self.viterbi_decode(inputs, self.sequence_lengths)\n",
        "        nb_classes = self.input_spec[0].shape[2]\n",
        "        y_pred_one_hot = K.one_hot(y_pred, nb_classes)\n",
        "\n",
        "        return K.in_train_phase(inputs, y_pred_one_hot)\n",
        "\n",
        "    def loss(self, y_true, y_pred):\n",
        "        y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')\n",
        "        log_likelihood, self.transition_params = tfa.text.crf.crf_log_likelihood(\n",
        "            y_pred, y_true, self.sequence_lengths, self.transition_params)\n",
        "        loss = tf.reduce_mean(-log_likelihood)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'transition_params': K.eval(self.transition_params),\n",
        "        }\n",
        "        base_config = super(CRFLayer, self).get_config()\n",
        "\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def create_custom_objects():\n",
        "    instanceHolder = {'instance': None}\n",
        "\n",
        "    class ClassWrapper(CRFLayer):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            instanceHolder['instance'] = self\n",
        "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def loss(*args):\n",
        "        method = getattr(instanceHolder['instance'], 'loss')\n",
        "        return method(*args)\n",
        "\n",
        "    return {'CRFLayer': ClassWrapper, 'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bcRf7zuPp7HD"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "# base_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dQ6RfcCYq00q"
      },
      "outputs": [],
      "source": [
        "def createToxicModelWithGivenBaseModel(max_input_length,base_model):\n",
        "    input_ids_layer = layers.Input(shape=(max_input_length,),name=\"encoder_input_ids\",dtype=tf.int32)\n",
        "    input_attention_mask_layer = layers.Input(shape=(max_input_length,),name=\"encoder_attention_mask\",dtype=tf.int32)\n",
        "    input_length = layers.Input(shape=(1,),name=\"length\",dtype=tf.int32)\n",
        "    base_model.trainable = True\n",
        "    base_model = base_model(input_ids_layer,attention_mask=input_attention_mask_layer,return_dict=True)\n",
        "    output = layers.Dropout(0.1)(base_model.last_hidden_state)\n",
        "    output = layers.Dense(1024,activation=\"relu\")(output)\n",
        "    output = layers.Dropout(0.1)(output)\n",
        "    output = layers.Dense(1024,activation=\"relu\")(output)\n",
        "    output = layers.Dense(3,activation=\"linear\")(output)\n",
        "    crf = CRFLayer()\n",
        "    output = crf(inputs=[output,input_length])\n",
        "    model = models.Model(inputs=[input_ids_layer,input_attention_mask_layer,input_length],outputs=output)\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=3e-5),loss=crf.loss,metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GrQhJqxLq4UC"
      },
      "outputs": [],
      "source": [
        "max_length = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Hp1x4QrE1o",
        "outputId": "a4571ff6-0ac7-4df0-88c0-79be04f4a288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-13b86bb0ab0a>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output = np.zeros(max_length*3,dtype=np.float).reshape((max_length,3))\n"
          ]
        }
      ],
      "source": [
        "texts = train_set['text'].to_numpy()\n",
        "targets = createNEROutputs(texts, train_set['spans'], max_length, tokenizer)\n",
        "all_spans = train_set['spans'].to_numpy()\n",
        "result_test = []\n",
        "result_train = []\n",
        "kf = KFold(n_splits = 5)\n",
        "train_test_indices = []\n",
        "for train_index,test_index in kf.split(texts):\n",
        "    train_test_indices.append((train_index, test_index))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_spans[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFCBnGUSp_eO",
        "outputId": "6a46313b-8681-4aed-b056-5b38b8e1cacc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394]),\n",
              "       list([108, 109, 110, 111, 112]),\n",
              "       list([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]),\n",
              "       ...,\n",
              "       list([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]),\n",
              "       list([5, 6, 7, 8, 9, 10, 11]),\n",
              "       list([106, 107, 108, 109, 110, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMstOsOPrLXZ",
        "outputId": "364673c9-b7f2-4156-9358-b30a027b7f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "397/397 [==============================] - 664s 2s/step - loss: 11.2226 - accuracy: 0.1091\n",
            "Epoch 2/2\n",
            "397/397 [==============================] - 660s 2s/step - loss: 9.7453 - accuracy: 0.1098\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "test F1 = 0.646661\n",
            "199/199 [==============================] - 212s 1s/step\n",
            "train F1 = 0.655973\n"
          ]
        }
      ],
      "source": [
        "train_index,test_index = train_test_indices.pop()\n",
        "x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n",
        "y_train , y_test = targets[train_index] , targets[test_index]\n",
        "model = None\n",
        "base_model = None\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)\n",
        "train_data = createInputForNER(x_train,max_length,tokenizer)\n",
        "test_data = createInputForNER(x_test,max_length,tokenizer)\n",
        "spans_test = all_spans[test_index]\n",
        "spans_train = all_spans[train_index]\n",
        "model.fit(train_data,y_train,batch_size=16,epochs=2)\n",
        "preds = model.predict(test_data)\n",
        "indices = createIndicesForNERModel(preds,x_test,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_test)\n",
        "print(\"test F1 = %f\"%(f1_toxic))\n",
        "result_test.append(f1_toxic)\n",
        "preds = model.predict(train_data)\n",
        "indices = createIndicesForNERModel(preds,x_train,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_train)\n",
        "print(\"train F1 = %f\"%(f1_toxic))\n",
        "result_train.append(f1_toxic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VwUIQWNJrRvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded096a3-af35-4853-c2fc-2c98175f8d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-13b86bb0ab0a>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output = np.zeros(max_length*3,dtype=np.float).reshape((max_length,3))\n"
          ]
        }
      ],
      "source": [
        "texts_test = test_set['text'].to_numpy()\n",
        "targets_test = createNEROutputs(texts, test_set['spans'], max_length, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test1 = list(texts_test)\n",
        "y_test1 = targets_test"
      ],
      "metadata": {
        "id": "nakH8oh8n14N"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OPGLhtApRml",
        "outputId": "c592426c-1a01-4818-90e7-ea68d3f3f9c0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_test1 = []\n",
        "test_data1 = createInputForNER(x_test1,max_length,tokenizer)\n",
        "spans_test1 = test_set['spans'].to_numpy()\n",
        "preds1 = model.predict(test_data1)\n",
        "indices1 = createIndicesForNERModel(preds1,x_test1,tokenizer)\n",
        "f1_toxic1 = avg_f1(indices1,spans_test1)\n",
        "print(\"test F1 = %f\"%(f1_toxic1))\n",
        "result_test1.append(f1_toxic1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az1kgb3nq1dt",
        "outputId": "5d88c7dc-cf0f-4111-fc1b-846c09eb24f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 67s 1s/step\n",
            "test F1 = 0.177506\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}